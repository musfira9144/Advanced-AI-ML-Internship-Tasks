# ğŸ§  Task 3: Context-Aware Chatbot (RAG with LangChain & Groq)

## ğŸ“Œ Overview
This project implements a **context-aware conversational chatbot** using **Retrieval-Augmented Generation (RAG)**.  
The chatbot is capable of:
- Remembering past conversation context
- Retrieving relevant information from a custom knowledge base
- Generating accurate responses using a Large Language Model (LLM)

This task demonstrates **real-world LLM system design**, combining vector databases, embeddings, memory, and LLM inference.

---

## ğŸ¯ Objectives
- Build a conversational chatbot with memory
- Implement Retrieval-Augmented Generation (RAG)
- Store and retrieve documents using vector search
- Deploy the chatbot using **Streamlit**

---

## ğŸ§° Tech Stack
- **Python**
- **LangChain**
- **Groq LLM (LLaMA 3)**
- **FAISS** â€“ Vector Database
- **Sentence-Transformers** â€“ Embeddings
- **Streamlit** â€“ Web UI
- **Google Colab** â€“ Model development

---

## ğŸ—‚ï¸ Project Structure
Task-3-Context-Aware-Chatbot-RAG/ 
â”œâ”€â”€ app.py 
â”œâ”€â”€ requirements.txt 
â”œâ”€â”€ data/ 
â”‚ â””â”€â”€ knowledge.txt 
â”œâ”€â”€ notebook/ 
â”‚ â””â”€â”€ RAG_Chatbot.ipynb 
â”œâ”€â”€ README.md

---

## ğŸ§  How It Works (Architecture)
1. **Document Loading**  
   Custom text documents are loaded as the chatbotâ€™s knowledge base.

2. **Text Chunking**  
   Documents are split into smaller chunks for better retrieval.

3. **Embedding Generation**  
   Each chunk is converted into vector embeddings using Sentence-Transformers.

4. **Vector Storage**  
   Embeddings are stored in a FAISS vector database.

5. **Context Memory**  
   Chat history is stored using LangChainâ€™s conversation memory.

6. **LLM Response Generation**  
   Groqâ€™s LLaMA 3 model generates responses using retrieved context + chat history.

---

## ğŸŒ Deployment

The chatbot is deployed using Streamlit.

## ğŸ”— Live App:
(Add your Streamlit Cloud link here once deployed)

---

## ğŸ“ˆ Skills Gained

- Conversational AI Development

- Retrieval-Augmented Generation (RAG)

- Vector Embeddings & Similarity Search

- LangChain Pipelines

- LLM Integration (Groq / LLaMA 3)

- Streamlit Deployment